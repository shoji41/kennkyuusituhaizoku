{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shoji41/kennkyuusituhaizoku/blob/main/2026_1_19%E3%80%80%E7%A0%94%E7%A9%B6%E5%AE%A4%E9%85%8D%E5%B1%9E%E3%80%80%E7%9C%BC%E7%9E%BC%E3%82%BB%E3%82%B0%E3%83%A1%E3%83%B3%E3%83%86%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pzsm1rVI7pL1"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ykitaguchi77/Eyelid_segmentation_inference/blob/main/inference_SegFormer_amodal.ipynb)\n",
        "\n",
        "# SegFormer-B0 Amodal セグメンテーション推論\n",
        "\n",
        "SegFormer-B0モデルを使用した眼領域のAmodal（重なりを許容する）セグメンテーション推論\n",
        "\n",
        "## パイプライン構成\n",
        "1. **Stage 1**: YOLO検出モデルで顔画像から両眼を検出 (Right_eye, Left_eye)\n",
        "2. **Stage 2**: 検出したBBoxからROI（関心領域）を512x512で切り出し\n",
        "3. **Stage 3**: SegFormer-B0でROI画像をセグメンテーション\n",
        "\n",
        "## 出力マスク（3チャンネル、Multi-label）\n",
        "| チャンネル | 名前 | 説明 | 表示色 |\n",
        "|-----------|------|------|--------|\n",
        "| 0 | eyelid | 眼瞼（まぶた）全体 | 赤 |\n",
        "| 1 | iris | 虹彩（完全な楕円） | 緑 |\n",
        "| 2 | pupil | 瞳孔（完全な楕円） | 青 |"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Eb9OGV627uP2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6233a0-2595-4952-ec7d-83994d92953f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "__h92jk97pL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44c33d09-e6de-479f-8df4-e554555652f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.4.7-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch<2.10,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cpu)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<2.10,>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<2.10,>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.4.7-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.4.7 ultralytics-thop-2.0.18\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch バージョン: 2.9.0+cpu\n",
            "CUDA (GPU) 利用可能: False\n"
          ]
        }
      ],
      "source": [
        "# ===== Cell 1: ライブラリのインポート =====\n",
        "# 必要なライブラリを読み込みます\n",
        "\n",
        "!pip install ultralytics\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO  # YOLOv11検出モデル用\n",
        "from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor  # SegFormerモデル用\n",
        "\n",
        "# PyTorchとGPUの情報を表示\n",
        "print(f\"PyTorch バージョン: {torch.__version__}\")\n",
        "print(f\"CUDA (GPU) 利用可能: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU名: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aLfqKYdt7pL4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af6d90b-86a0-4058-be47-726bfba9c379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "モデルファイルをダウンロード中...\n",
            "--2026-01-27 04:12:59--  https://github.com/ykitaguchi77/Eyelid_segmentation_inference/raw/main/YOLO11l-detect.pt\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2026-01-27 04:12:59 ERROR 404: Not Found.\n",
            "\n",
            "--2026-01-27 04:12:59--  https://github.com/ykitaguchi77/Eyelid_segmentation_inference/raw/main/segformer_b3_amodal_blur_best.pth\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2026-01-27 04:13:00 ERROR 404: Not Found.\n",
            "\n",
            "--2026-01-27 04:13:00--  https://github.com/ykitaguchi77/Eyelid_segmentation_inference/raw/main/sample_image.png\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2026-01-27 04:13:00 ERROR 404: Not Found.\n",
            "\n",
            "--2026-01-27 04:13:00--  https://github.com/ykitaguchi77/Eyelid_segmentation_inference/raw/main/sample_image_2.png\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2026-01-27 04:13:00 ERROR 404: Not Found.\n",
            "\n",
            "ダウンロード完了!\n",
            "==================================================\n",
            "設定情報\n",
            "==================================================\n",
            "検出モデル: /content/drive/MyDrive/YOLO11l-detect.pt\n",
            "SegFormerモデル: /content/drive/MyDrive/AI_laboratory_course/眼瞼/segformer_b3_amodal_blur_best.pth\n",
            "デバイス: cpu\n",
            "ROIサイズ: 512x512\n",
            "拡張率: 0.25 (25%)\n",
            "閾値: 0.5\n"
          ]
        }
      ],
      "source": [
        "# ===== Cell 2: 設定およびモデルファイルのダウンロード =====\n",
        "# モデルパスや推論パラメータを設定し、必要なモデルファイルをダウンロードします\n",
        "\n",
        "# プロジェクトのルートディレクトリ\n",
        "PROJECT_ROOT = Path(\".\").resolve()\n",
        "\n",
        "# モデルファイルのダウンロード\n",
        "print(\"モデルファイルをダウンロード中...\")\n",
        "!wget -nc https://github.com/ykitaguchi77/Eyelid_segmentation_inference/raw/main/YOLO11l-detect.pt -P {PROJECT_ROOT}\n",
        "!wget -nc https://github.com/ykitaguchi77/Eyelid_segmentation_inference/raw/main/segformer_b3_amodal_blur_best.pth -P {PROJECT_ROOT}\n",
        "!wget -nc https://github.com/ykitaguchi77/Eyelid_segmentation_inference/raw/main/sample_image.png -P {PROJECT_ROOT}\n",
        "!wget -nc https://github.com/ykitaguchi77/Eyelid_segmentation_inference/raw/main/sample_image_2.png -P {PROJECT_ROOT}\n",
        "print(\"ダウンロード完了!\")\n",
        "\n",
        "# Stage 1: YOLO検出モデル（両眼の位置を検出）\n",
        "#DETECT_MODEL_PATH = PROJECT_ROOT / \"YOLO11l-detect.pt\"\n",
        "DETECT_MODEL_PATH = \"/content/drive/MyDrive/YOLO11l-detect.pt\"\n",
        "\n",
        "# Stage 2: SegFormer Amodalモデル（眼領域をセグメンテーション）\n",
        "SEGFORMER_MODEL_NAME = \"nvidia/segformer-b0-finetuned-ade-512-512\"  # ベースモデル\n",
        "SEGFORMER_MODEL_PATH = PROJECT_ROOT / \"/content/drive/MyDrive/AI_laboratory_course/眼瞼/segformer_b3_amodal_blur_best.pth\"\n",
        "\n",
        "# 推論パラメータ\n",
        "IMAGE_SIZE = 512          # ROIのサイズ（512x512ピクセル）\n",
        "NUM_CHANNELS = 3          # 出力チャンネル数（eyelid, iris, pupil）\n",
        "THRESHOLD = 0.5           # マスクの2値化閾値（0.5以上を検出領域とする）\n",
        "EXPANSION_RATIO = 0.25    # ROI抽出時の拡張率（25%のマージンを追加）\n",
        "\n",
        "# デバイス設定（GPUがあればGPU、なければCPU）\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# サンプル画像のパス\n",
        "SAMPLE_IMAGES = [\n",
        "   \"/content/drive/MyDrive/AI_laboratory_course/face.jpg\"\n",
        "]\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"設定情報\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"検出モデル: {DETECT_MODEL_PATH}\")\n",
        "print(f\"SegFormerモデル: {SEGFORMER_MODEL_PATH}\")\n",
        "print(f\"デバイス: {device}\")\n",
        "print(f\"ROIサイズ: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
        "print(f\"拡張率: {EXPANSION_RATIO} ({int(EXPANSION_RATIO*100)}%)\")\n",
        "print(f\"閾値: {THRESHOLD}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XyQGNH0O7pL4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558,
          "referenced_widgets": [
            "90044ecf62af4895a60e8eb72c53f85d",
            "7545a6a7c2354a3e9460c76f8c4dc43e",
            "5221be0c9527473b805fbd0cf6b2d374",
            "5fcc728928e24a6db361faa0716321af",
            "de0adc0b4fb342d88df3de62d6bb78bd",
            "3fcd33fdba23414f9a7205a43ac7cc21",
            "b5c569e186f4421cbea171a9e281b6d0",
            "3bfa29783ff74d9ea257640e32152f04",
            "82bc22124da64cd4a08d2ec58ed9f0c3",
            "25469f776be5473a92cedf061f8361a5",
            "3548f69197a442ae91763fc574c464df",
            "1bd4eb907dbf4e15aac2260e19123648",
            "c917cd8289934c09a1f1ab7a8c1be104",
            "421c15fcb8cb40f68cc0628341f67abc",
            "4d05153b0ef14f8b9139d61f8c4ea733",
            "3d69cbfce2e4434f83ccb040cf07fbb9",
            "8d341df37f2142db871598186e9786a7",
            "c332b0cb2f1d4190a8ec59fdf308f2ea",
            "b14b3f8e2700466aa542b7eec4653378",
            "d3536a7646004762baa9fabf33e721c1",
            "4f22c50a0c454774a5a45482f3120975",
            "50f9eda0db3945b0bdd9842cb7ff58dd",
            "56c6d8e4fcdd48eab5a22b66eb94ab13",
            "4b437db4526b4ac0933350ea0b4f864f",
            "9a5d1e03e02549b58191e5341973c13c",
            "39fe3e508c744d21b886b7b9e1849aee",
            "e287191aed26450a9207ae9c11174436",
            "6032dba100e647c49ac3331b184837f4",
            "a399d7f4174d4c64832a21d8ba380d60",
            "f62f3deaa7a943c09e88318ed43fb13b",
            "ecb874ab490a4afd8ae9d65ac01e5d4f",
            "dad137291d3d46ba9d638be9556ffc18",
            "fe424c210ef2461682475bb57de08d75"
          ]
        },
        "outputId": "b39c0adc-d685-49c0-a58f-fdf014cb37c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "モデルの読み込み\n",
            "==================================================\n",
            "\n",
            "[Stage 1] YOLO検出モデルを読み込み中...\n",
            "  読み込み完了!\n",
            "  検出クラス: {0: 'Right_eye', 1: 'Left_eye'}\n",
            "\n",
            "[Stage 2] SegFormerモデルを読み込み中...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90044ecf62af4895a60e8eb72c53f85d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/190M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bd4eb907dbf4e15aac2260e19123648"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b3-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([3, 768, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/189M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56c6d8e4fcdd48eab5a22b66eb94ab13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  読み込み完了!\n",
            "  学習エポック: 36\n",
            "  検証Dice: 0.9415\n",
            "    - Eyelid: 0.9649\n",
            "    - Iris: 0.9509\n",
            "    - Pupil: 0.9088\n"
          ]
        }
      ],
      "source": [
        "# ===== Cell 3: モデルの読み込み =====\n",
        "# Stage1（検出）とStage2（セグメンテーション）のモデルを読み込みます\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "SEGFORMER_MODEL_PATH = Path(\"/content/drive/MyDrive/AI_laboratory_course/眼瞼/segformer_b3_amodal_blur_best.pth\")\n",
        "print(\"=\" * 50)\n",
        "print(\"モデルの読み込み\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# ----- Stage 1: YOLO検出モデル -----\n",
        "print(\"\\n[Stage 1] YOLO検出モデルを読み込み中...\")\n",
        "detect_model = YOLO(str(DETECT_MODEL_PATH))\n",
        "print(f\"  読み込み完了!\")\n",
        "print(f\"  検出クラス: {detect_model.names}\")\n",
        "\n",
        "# ----- Stage 2: SegFormerモデル -----\n",
        "print(\"\\n[Stage 2] SegFormerモデルを読み込み中...\")\n",
        "\n",
        "def create_segformer_model(num_labels=3):\n",
        "    \"\"\"SegFormer-B0モデルを作成（3チャンネル出力）\"\"\"\n",
        "    # 以前のバージョンではB0モデルを読み込んでいましたが、チェックポイントはB3モデルのようです。\n",
        "    # チェックポイントのモデルと一致させるため、B3モデルを読み込むように変更します。\n",
        "    model = SegformerForSemanticSegmentation.from_pretrained(\n",
        "        \"nvidia/segformer-b3-finetuned-ade-512-512\", # SEGFORMER_MODEL_NAME を B3 に変更\n",
        "        num_labels=num_labels,\n",
        "        ignore_mismatched_sizes=True\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# モデルファイルの存在確認\n",
        "if not SEGFORMER_MODEL_PATH.exists():\n",
        "    raise FileNotFoundError(f\"モデルが見つかりません: {SEGFORMER_MODEL_PATH}\")\n",
        "\n",
        "# モデルを作成し、学習済み重みを読み込み\n",
        "seg_model = create_segformer_model(num_labels=NUM_CHANNELS).to(device)\n",
        "checkpoint = torch.load(SEGFORMER_MODEL_PATH, map_location=device, weights_only=False)\n",
        "seg_model.load_state_dict(checkpoint[\"model\"])\n",
        "seg_model.eval()  # 推論モードに設定\n",
        "\n",
        "print(f\"  読み込み完了!\")\n",
        "print(f\"  学習エポック: {checkpoint['epoch']}\")\n",
        "print(f\"  検証Dice: {checkpoint['val_dice']['mean']:.4f}\")\n",
        "print(f\"    - Eyelid: {checkpoint['val_dice']['eyelid']:.4f}\")\n",
        "print(f\"    - Iris: {checkpoint['val_dice']['iris']:.4f}\")\n",
        "print(f\"    - Pupil: {checkpoint['val_dice']['pupil']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI24ZWHP7pL4"
      },
      "outputs": [],
      "source": [
        "# ===== Cell 4: 入力画像の読み込みと表示 =====\n",
        "# 推論に使用する画像を読み込み、表示します\n",
        "\n",
        "# 使用する画像（最初のサンプル画像）\n",
        "IMAGE_PATH = SAMPLE_IMAGES[0]\n",
        "\n",
        "# 画像を読み込み\n",
        "img = cv2.imread(str(IMAGE_PATH))\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # BGRからRGBに変換（表示用）\n",
        "\n",
        "print(f\"入力画像: {IMAGE_PATH}\")\n",
        "print(f\"画像サイズ: {img.shape[1]}x{img.shape[0]} ピクセル\")\n",
        "\n",
        "# 元画像を表示\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img_rgb)\n",
        "plt.title(f\"Input Image: {IMAGE_PATH}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEuyf-hp7pL5"
      },
      "outputs": [],
      "source": [
        "# ===== Cell 5: Stage 1 - 眼の検出 =====\n",
        "# YOLOモデルで顔画像から両眼の位置を検出します\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"Stage 1: 眼の検出\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 検出を実行\n",
        "detect_results = detect_model.predict(\n",
        "    source=img,\n",
        "    conf=0.25,   # 信頼度閾値（25%以上を検出）\n",
        "    iou=0.45,    # NMS（非最大値抑制）のIoU閾値\n",
        "    verbose=False\n",
        ")[0]\n",
        "\n",
        "print(f\"\\n検出数: {len(detect_results.boxes)} 眼\")\n",
        "\n",
        "# 検出結果の詳細を表示\n",
        "for i, box in enumerate(detect_results.boxes):\n",
        "    cls_id = int(box.cls[0])\n",
        "    cls_name = detect_model.names[cls_id]\n",
        "    conf = float(box.conf[0])\n",
        "    xyxy = box.xyxy[0].cpu().numpy()\n",
        "\n",
        "    print(f\"\\n[{i+1}] {cls_name}\")\n",
        "    print(f\"    信頼度: {conf:.3f} ({conf*100:.1f}%)\")\n",
        "    print(f\"    BBox: x1={xyxy[0]:.0f}, y1={xyxy[1]:.0f}, x2={xyxy[2]:.0f}, y2={xyxy[3]:.0f}\")\n",
        "\n",
        "# 検出結果を可視化\n",
        "result_img = detect_results.plot()\n",
        "result_img_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(result_img_rgb)\n",
        "plt.title(\"Detection Result (Red/Blue: Detected Eyes)\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "68vGad6n7pL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b8720a5-b18e-49c6-f715-b64bad4a2899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROI抽出関数を定義しました\n"
          ]
        }
      ],
      "source": [
        "# ===== Cell 6: ROI抽出関数の定義 =====\n",
        "# 検出したBBoxから眼領域（ROI）を切り出す関数を定義します\n",
        "\n",
        "def extract_roi(image, bbox, roi_size=512, expansion_ratio=0.25):\n",
        "    \"\"\"\n",
        "    検出したBBoxからROI（関心領域）を抽出\n",
        "\n",
        "    処理の流れ:\n",
        "    1. BBoxの中心を計算\n",
        "    2. 正方形にするため、長辺に合わせる\n",
        "    3. マージン（expansion_ratio）を追加\n",
        "    4. 画像境界をはみ出す場合は黒でパディング\n",
        "    5. 指定サイズ（roi_size）にリサイズ\n",
        "\n",
        "    Args:\n",
        "        image: 入力画像（BGR）\n",
        "        bbox: バウンディングボックス [x1, y1, x2, y2]\n",
        "        roi_size: 出力ROIのサイズ（デフォルト512x512）\n",
        "        expansion_ratio: 拡張率（デフォルト25%）\n",
        "\n",
        "    Returns:\n",
        "        roi: 抽出したROI画像\n",
        "        transform_info: 座標変換用の情報（元画像への逆変換に使用）\n",
        "    \"\"\"\n",
        "    h, w = image.shape[:2]\n",
        "    x1, y1, x2, y2 = bbox\n",
        "\n",
        "    # BBoxの中心座標\n",
        "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "\n",
        "    # 正方形化 + マージン追加後の辺の長さ\n",
        "    side = max(x2 - x1, y2 - y1) * (1 + 2 * expansion_ratio)\n",
        "\n",
        "    # 拡張後の座標\n",
        "    nx1, ny1 = int(cx - side / 2), int(cy - side / 2)\n",
        "    nx2, ny2 = int(cx + side / 2), int(cy + side / 2)\n",
        "\n",
        "    # 画像境界をはみ出す場合のパディング量\n",
        "    pad_top = max(0, -ny1)\n",
        "    pad_bottom = max(0, ny2 - h)\n",
        "    pad_left = max(0, -nx1)\n",
        "    pad_right = max(0, nx2 - w)\n",
        "\n",
        "    # 画像範囲内のみを切り出し\n",
        "    roi = image[max(0, ny1):min(h, ny2), max(0, nx1):min(w, nx2)].copy()\n",
        "\n",
        "    # はみ出した部分は黒（0, 0, 0）でパディング\n",
        "    if pad_top or pad_bottom or pad_left or pad_right:\n",
        "        roi = cv2.copyMakeBorder(roi, pad_top, pad_bottom, pad_left, pad_right,\n",
        "                                  cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
        "\n",
        "    # 座標変換情報を保存（元画像への逆変換に使用）\n",
        "    transform_info = {\n",
        "        'original_bbox': bbox,\n",
        "        'expanded_bbox': [nx1, ny1, nx2, ny2],\n",
        "        'padding': [pad_top, pad_bottom, pad_left, pad_right],\n",
        "        'scale': roi_size / side,\n",
        "        'center': (cx, cy),\n",
        "        'side': side\n",
        "    }\n",
        "\n",
        "    # 指定サイズにリサイズ\n",
        "    return cv2.resize(roi, (roi_size, roi_size)), transform_info\n",
        "\n",
        "\n",
        "print(\"ROI抽出関数を定義しました\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsB9a48E7pL5"
      },
      "outputs": [],
      "source": [
        "# ===== Cell 7: Stage 2 - ROIの抽出と表示 =====\n",
        "# 検出したBBoxからROIを切り出し、表示します\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"Stage 2: ROI抽出\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 各眼のROIを抽出\n",
        "rois = []         # ROI画像を格納\n",
        "eye_names = []    # 眼の名前（Right_eye / Left_eye）\n",
        "bboxes = []       # 元のBBox\n",
        "transform_infos = []  # 座標変換情報\n",
        "\n",
        "for box in detect_results.boxes:\n",
        "    cls_name = detect_model.names[int(box.cls[0])]\n",
        "    bbox = box.xyxy[0].cpu().numpy()\n",
        "\n",
        "    # ROIを抽出\n",
        "    roi, transform_info = extract_roi(img, bbox, roi_size=IMAGE_SIZE, expansion_ratio=EXPANSION_RATIO)\n",
        "\n",
        "    rois.append(roi)\n",
        "    eye_names.append(cls_name)\n",
        "    bboxes.append(bbox)\n",
        "    transform_infos.append(transform_info)\n",
        "\n",
        "    print(f\"\\n{cls_name}: ROI抽出完了 ({IMAGE_SIZE}x{IMAGE_SIZE})\")\n",
        "\n",
        "# 抽出したROIを表示\n",
        "fig, axes = plt.subplots(1, len(rois), figsize=(6 * len(rois), 6))\n",
        "if len(rois) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for ax, roi, name in zip(axes, rois, eye_names):\n",
        "    ax.imshow(cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
        "    ax.set_title(f\"{name} ROI ({IMAGE_SIZE}x{IMAGE_SIZE})\")\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.suptitle(\"Extracted ROI Images\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGYsesxP7pL5"
      },
      "outputs": [],
      "source": [
        "# ===== Cell 8: SegFormer推論関数の定義 =====\n",
        "# SegFormerモデルでROI画像をセグメンテーションする関数を定義します\n",
        "\n",
        "def predict_amodal(model, roi_image, device, image_size=512, threshold=0.5):\n",
        "    \"\"\"\n",
        "    SegFormer Amodalモデルで推論を実行\n",
        "\n",
        "    Amodal（アモーダル）セグメンテーションとは:\n",
        "    - 各マスク（eyelid, iris, pupil）が独立して予測される\n",
        "    - マスク同士の重なりが許容される（pupil ⊂ iris ⊂ eyelid）\n",
        "    - 瞼で隠れた部分も含めた「完全な」領域を予測\n",
        "\n",
        "    Args:\n",
        "        model: SegFormerモデル\n",
        "        roi_image: ROI画像（RGBのnumpy配列）\n",
        "        device: 推論デバイス（cuda/cpu）\n",
        "        image_size: モデルの入力サイズ\n",
        "        threshold: 2値化閾値\n",
        "\n",
        "    Returns:\n",
        "        masks: 各チャンネルの2値マスク {'eyelid', 'iris', 'pupil'}\n",
        "        probs: 各チャンネルの確率マップ\n",
        "    \"\"\"\n",
        "    # RGBに変換（必要な場合）\n",
        "    if roi_image.shape[-1] == 3 and len(roi_image.shape) == 3:\n",
        "        img_rgb = roi_image\n",
        "    else:\n",
        "        img_rgb = cv2.cvtColor(roi_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # SegFormer用の前処理（正規化など）\n",
        "    processor = SegformerImageProcessor.from_pretrained(\n",
        "        SEGFORMER_MODEL_NAME, do_resize=False, do_rescale=True, do_normalize=True\n",
        "    )\n",
        "    inputs = processor(images=img_rgb, return_tensors=\"pt\")\n",
        "    pixel_values = inputs[\"pixel_values\"].to(device)\n",
        "\n",
        "    # 推論を実行\n",
        "    with torch.no_grad():\n",
        "        outputs = model(pixel_values=pixel_values)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # SegFormerの出力は入力より小さいため、元のサイズに拡大\n",
        "        if logits.shape[-2:] != (image_size, image_size):\n",
        "            logits = F.interpolate(\n",
        "                logits, size=(image_size, image_size),\n",
        "                mode='bilinear', align_corners=False\n",
        "            )\n",
        "\n",
        "        # Sigmoid関数で確率に変換（Multi-labelなのでSoftmaxではなくSigmoid）\n",
        "        probs = torch.sigmoid(logits).squeeze(0).cpu().numpy()\n",
        "\n",
        "    # マスクを作成（閾値以上を検出領域とする）\n",
        "    channel_names = ['eyelid', 'iris', 'pupil']\n",
        "    masks = {}\n",
        "    probs_dict = {}\n",
        "\n",
        "    for c, name in enumerate(channel_names):\n",
        "        probs_dict[name] = probs[c]\n",
        "        masks[name] = ((probs[c] > threshold) * 255).astype(np.uint8)\n",
        "\n",
        "    return masks, probs_dict\n",
        "\n",
        "\n",
        "print(\"SegFormer推論関数を定義しました\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Op-bwb6t7pL5"
      },
      "outputs": [],
      "source": [
        "# ===== Cell 9: Stage 3 - セグメンテーション推論 =====\n",
        "# 各ROIに対してSegFormerでセグメンテーション推論を実行します\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"Stage 3: セグメンテーション推論\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 各ROIに対してセグメンテーション推論を実行\n",
        "seg_results = []  # セグメンテーション結果を格納\n",
        "\n",
        "for roi, name in zip(rois, eye_names):\n",
        "    # ROIをRGBに変換\n",
        "    roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # 推論を実行\n",
        "    masks, probs = predict_amodal(seg_model, roi_rgb, device, IMAGE_SIZE, THRESHOLD)\n",
        "\n",
        "    seg_results.append({\n",
        "        'eye_name': name,\n",
        "        'roi_rgb': roi_rgb,\n",
        "        'masks': masks,\n",
        "        'probs': probs\n",
        "    })\n",
        "\n",
        "    # 結果を表示\n",
        "    total_pixels = IMAGE_SIZE * IMAGE_SIZE\n",
        "    print(f\"\\n{name}: セグメンテーション完了\")\n",
        "    print(f\"  Eyelid: {(masks['eyelid'] > 0).sum():>6} pixels ({100 * (masks['eyelid'] > 0).sum() / total_pixels:.1f}%)\")\n",
        "    print(f\"  Iris:   {(masks['iris'] > 0).sum():>6} pixels ({100 * (masks['iris'] > 0).sum() / total_pixels:.1f}%)\")\n",
        "    print(f\"  Pupil:  {(masks['pupil'] > 0).sum():>6} pixels ({100 * (masks['pupil'] > 0).sum() / total_pixels:.1f}%)\")\n",
        "\n",
        "print(\"\\n全てのROIの推論が完了しました\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAB9-vxF7pL5"
      },
      "outputs": [],
      "source": [
        "# ===== Cell 10: セグメンテーション結果の可視化 =====\n",
        "# 各眼のセグメンテーション結果を表示します\n",
        "# 表示内容: ROI | Eyelid Mask | Iris Mask | Pupil Mask | Merged\n",
        "\n",
        "def create_merged_overlay(img_rgb, eyelid_mask, iris_mask, pupil_mask, alpha=0.5):\n",
        "    \"\"\"\n",
        "    3つのマスクを重ねたオーバーレイ画像を作成\n",
        "    色: Eyelid=赤, Iris=緑, Pupil=青\n",
        "    \"\"\"\n",
        "    h, w = img_rgb.shape[:2]\n",
        "    color_mask = np.zeros((h, w, 3), dtype=np.float32)\n",
        "\n",
        "    # 各マスクに色を割り当て\n",
        "    color_mask[eyelid_mask > 0, 0] = 255  # 赤: Eyelid\n",
        "    color_mask[iris_mask > 0, 1] = 255    # 緑: Iris\n",
        "    color_mask[pupil_mask > 0, 2] = 255   # 青: Pupil\n",
        "\n",
        "    # 元画像とブレンド\n",
        "    overlay = img_rgb.astype(np.float32) * (1 - alpha) + color_mask * alpha\n",
        "    overlay = np.clip(overlay, 0, 255).astype(np.uint8)\n",
        "\n",
        "    return overlay\n",
        "\n",
        "\n",
        "# 各眼の結果を表示\n",
        "for res in seg_results:\n",
        "    roi_rgb = res['roi_rgb']\n",
        "    masks = res['masks']\n",
        "    eye_name = res['eye_name']\n",
        "\n",
        "    # マージ画像を作成\n",
        "    merged = create_merged_overlay(roi_rgb, masks['eyelid'], masks['iris'], masks['pupil'])\n",
        "\n",
        "    # 5列で表示: ROI | Eyelid | Iris | Pupil | Merged\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
        "\n",
        "    # ROI（元画像）\n",
        "    axes[0].imshow(roi_rgb)\n",
        "    axes[0].set_title(\"ROI (512x512)\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    # Eyelidマスク（赤系カラーマップ）\n",
        "    axes[1].imshow(masks['eyelid'], cmap='Reds', vmin=0, vmax=255)\n",
        "    axes[1].set_title(\"Eyelid Mask\")\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    # Irisマスク（緑系カラーマップ）\n",
        "    axes[2].imshow(masks['iris'], cmap='Greens', vmin=0, vmax=255)\n",
        "    axes[2].set_title(\"Iris Mask\")\n",
        "    axes[2].axis(\"off\")\n",
        "\n",
        "    # Pupilマスク（青系カラーマップ）\n",
        "    axes[3].imshow(masks['pupil'], cmap='Blues', vmin=0, vmax=255)\n",
        "    axes[3].set_title(\"Pupil Mask\")\n",
        "    axes[3].axis(\"off\")\n",
        "\n",
        "    # マージ画像（3マスクを重畳表示）\n",
        "    axes[4].imshow(merged)\n",
        "    axes[4].set_title(\"Merged (R=Eyelid, G=Iris, B=Pupil)\")\n",
        "    axes[4].axis(\"off\")\n",
        "\n",
        "    fig.suptitle(f\"{eye_name} Segmentation Result\", fontsize=14, y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36DPktN27pL6"
      },
      "outputs": [],
      "source": [
        "# ===== Cell 11: 結果の保存 =====\n",
        "# セグメンテーション結果をファイルに保存します\n",
        "\n",
        "def save_results(image_path, seg_results, output_dir=None):\n",
        "    \"\"\"\n",
        "    セグメンテーション結果をファイルに保存\n",
        "\n",
        "    保存されるファイル（各眼ごと）:\n",
        "    - {画像名}_{眼名}_roi.png        : 切り出したROI画像\n",
        "    - {画像名}_{眼名}_eyelid_mask.png : Eyelidマスク\n",
        "    - {画像名}_{眼名}_iris_mask.png   : Irisマスク\n",
        "    - {画像名}_{眼名}_pupil_mask.png  : Pupilマスク\n",
        "    - {画像名}_{眼名}_merged.png      : マージ画像\n",
        "    \"\"\"\n",
        "    image_path = Path(image_path)\n",
        "    if output_dir is None:\n",
        "        output_dir = image_path.parent\n",
        "    output_dir = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    stem = image_path.stem  # 拡張子を除いたファイル名\n",
        "\n",
        "    for res in seg_results:\n",
        "        eye_name = res['eye_name']\n",
        "        roi_rgb = res['roi_rgb']\n",
        "        masks = res['masks']\n",
        "        merged = create_merged_overlay(roi_rgb, masks['eyelid'], masks['iris'], masks['pupil'])\n",
        "\n",
        "        # ROI画像を保存（RGBからBGRに変換）\n",
        "        cv2.imwrite(str(output_dir / f\"{stem}_{eye_name}_roi.png\"),\n",
        "                    cv2.cvtColor(roi_rgb, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "        # 各マスクを保存\n",
        "        cv2.imwrite(str(output_dir / f\"{stem}_{eye_name}_eyelid_mask.png\"), masks['eyelid'])\n",
        "        cv2.imwrite(str(output_dir / f\"{stem}_{eye_name}_iris_mask.png\"), masks['iris'])\n",
        "        cv2.imwrite(str(output_dir / f\"{stem}_{eye_name}_pupil_mask.png\"), masks['pupil'])\n",
        "\n",
        "        # マージ画像を保存\n",
        "        cv2.imwrite(str(output_dir / f\"{stem}_{eye_name}_merged.png\"),\n",
        "                    cv2.cvtColor(merged, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "        print(f\"保存完了: {stem}_{eye_name}_*.png\")\n",
        "\n",
        "\n",
        "# 結果を保存（コメントを外して実行）\n",
        "# save_results(IMAGE_PATH, seg_results)\n",
        "\n",
        "print(\"保存関数を定義しました\")\n",
        "print(\"使い方: save_results(IMAGE_PATH, seg_results)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWv_pp0F7pL6"
      },
      "outputs": [],
      "source": [
        "# ===== Cell 12: 別の画像で推論（オプション） =====\n",
        "# 他のサンプル画像がある場合、ここで推論を実行できます\n",
        "\n",
        "# ========================================\n",
        "# ここに処理したい画像のパスを指定してください\n",
        "# ========================================\n",
        "TARGET_IMAGE_PATH = PROJECT_ROOT / \"sample_image_2.png\"\n",
        "# TARGET_IMAGE_PATH = Path(r\"C:\\path\\to\\your\\image.png\")  # 任意の画像パス\n",
        "# ========================================\n",
        "\n",
        "\n",
        "def run_full_pipeline(image_path, detect_model, seg_model, device, visualize=True):\n",
        "    \"\"\"\n",
        "    画像パスを指定して、検出からセグメンテーションまでの全パイプラインを実行\n",
        "\n",
        "    Args:\n",
        "        image_path: 入力画像のパス\n",
        "        detect_model: YOLO検出モデル\n",
        "        seg_model: SegFormerセグメンテーションモデル\n",
        "        device: 推論デバイス\n",
        "        visualize: 結果を表示するかどうか\n",
        "\n",
        "    Returns:\n",
        "        seg_results: セグメンテーション結果のリスト\n",
        "    \"\"\"\n",
        "    image_path = Path(image_path)\n",
        "    if not image_path.exists():\n",
        "        raise FileNotFoundError(f\"画像が見つかりません: {image_path}\")\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"処理中: {image_path.name}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # 画像を読み込み\n",
        "    img = cv2.imread(str(image_path))\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Stage 1: 検出\n",
        "    detect_results = detect_model.predict(source=img, conf=0.25, iou=0.45, verbose=False)[0]\n",
        "    print(f\"検出数: {len(detect_results.boxes)} 眼\")\n",
        "\n",
        "    if len(detect_results.boxes) == 0:\n",
        "        print(\"眼が検出されませんでした\")\n",
        "        return []\n",
        "\n",
        "    # Stage 2 & 3: ROI抽出とセグメンテーション\n",
        "    seg_results = []\n",
        "    for box in detect_results.boxes:\n",
        "        cls_name = detect_model.names[int(box.cls[0])]\n",
        "        bbox = box.xyxy[0].cpu().numpy()\n",
        "\n",
        "        roi, _ = extract_roi(img, bbox, IMAGE_SIZE, EXPANSION_RATIO)\n",
        "        roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
        "        masks, probs = predict_amodal(seg_model, roi_rgb, device, IMAGE_SIZE, THRESHOLD)\n",
        "\n",
        "        seg_results.append({\n",
        "            'eye_name': cls_name,\n",
        "            'roi_rgb': roi_rgb,\n",
        "            'masks': masks,\n",
        "            'probs': probs\n",
        "        })\n",
        "        print(f\"  {cls_name}: 推論完了\")\n",
        "\n",
        "    # 結果を表示\n",
        "    if visualize:\n",
        "        for res in seg_results:\n",
        "            roi_rgb = res['roi_rgb']\n",
        "            masks = res['masks']\n",
        "            merged = create_merged_overlay(roi_rgb, masks['eyelid'], masks['iris'], masks['pupil'])\n",
        "\n",
        "            fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
        "            axes[0].imshow(roi_rgb); axes[0].set_title(\"ROI\"); axes[0].axis('off')\n",
        "            axes[1].imshow(masks['eyelid'], cmap='Reds', vmin=0, vmax=255); axes[1].set_title(\"Eyelid\"); axes[1].axis('off')\n",
        "            axes[2].imshow(masks['iris'], cmap='Greens', vmin=0, vmax=255); axes[2].set_title(\"Iris\"); axes[2].axis('off')\n",
        "            axes[3].imshow(masks['pupil'], cmap='Blues', vmin=0, vmax=255); axes[3].set_title(\"Pupil\"); axes[3].axis('off')\n",
        "            axes[4].imshow(merged); axes[4].set_title(\"Merged\"); axes[4].axis('off')\n",
        "            fig.suptitle(f\"{res['eye_name']} - {image_path.name}\", fontsize=14)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "    return seg_results\n",
        "\n",
        "\n",
        "# 指定した画像で推論を実行\n",
        "if TARGET_IMAGE_PATH.exists():\n",
        "    print(f\"指定画像: {TARGET_IMAGE_PATH}\")\n",
        "    results_additional = run_full_pipeline(TARGET_IMAGE_PATH, detect_model, seg_model, device)\n",
        "else:\n",
        "    print(f\"画像が見つかりません: {TARGET_IMAGE_PATH}\")\n",
        "    print(\"TARGET_IMAGE_PATH に有効なパスを指定してください\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6qWdh-h7pL6"
      },
      "source": [
        "## まとめ\n",
        "\n",
        "このノートブックでは、SegFormer-B0 Amodalモデルを使用した眼領域のセグメンテーションを行いました。\n",
        "\n",
        "### パイプライン\n",
        "1. **Stage 1**: YOLOで顔画像から両眼を検出 (Right_eye, Left_eye)\n",
        "2. **Stage 2**: 検出したBBoxからROI (512x512) を切り出し\n",
        "3. **Stage 3**: SegFormer-B0でROI画像をセグメンテーション\n",
        "\n",
        "### 出力マスク\n",
        "| チャンネル | 名前 | 説明 | 色 |\n",
        "|-----------|------|------|----|\n",
        "| 0 | eyelid | 眼瞼全体（瞼で隠れた部分含む） | 赤 |\n",
        "| 1 | iris | 虹彩（完全な楕円） | 緑 |\n",
        "| 2 | pupil | 瞳孔（完全な楕円） | 青 |\n",
        "\n",
        "### 主な関数\n",
        "- `extract_roi()`: BBoxからROIを切り出し\n",
        "- `predict_amodal()`: SegFormerでセグメンテーション推論\n",
        "- `create_merged_overlay()`: 3マスクを重畳表示\n",
        "- `save_results()`: 結果をファイルに保存\n",
        "- `run_full_pipeline()`: 検出からセグメンテーションまで一括実行"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90044ecf62af4895a60e8eb72c53f85d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7545a6a7c2354a3e9460c76f8c4dc43e",
              "IPY_MODEL_5221be0c9527473b805fbd0cf6b2d374",
              "IPY_MODEL_5fcc728928e24a6db361faa0716321af"
            ],
            "layout": "IPY_MODEL_de0adc0b4fb342d88df3de62d6bb78bd"
          }
        },
        "7545a6a7c2354a3e9460c76f8c4dc43e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fcd33fdba23414f9a7205a43ac7cc21",
            "placeholder": "​",
            "style": "IPY_MODEL_b5c569e186f4421cbea171a9e281b6d0",
            "value": "config.json: "
          }
        },
        "5221be0c9527473b805fbd0cf6b2d374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bfa29783ff74d9ea257640e32152f04",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82bc22124da64cd4a08d2ec58ed9f0c3",
            "value": 1
          }
        },
        "5fcc728928e24a6db361faa0716321af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25469f776be5473a92cedf061f8361a5",
            "placeholder": "​",
            "style": "IPY_MODEL_3548f69197a442ae91763fc574c464df",
            "value": " 6.89k/? [00:00&lt;00:00, 118kB/s]"
          }
        },
        "de0adc0b4fb342d88df3de62d6bb78bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fcd33fdba23414f9a7205a43ac7cc21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5c569e186f4421cbea171a9e281b6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bfa29783ff74d9ea257640e32152f04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "82bc22124da64cd4a08d2ec58ed9f0c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25469f776be5473a92cedf061f8361a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3548f69197a442ae91763fc574c464df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bd4eb907dbf4e15aac2260e19123648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c917cd8289934c09a1f1ab7a8c1be104",
              "IPY_MODEL_421c15fcb8cb40f68cc0628341f67abc",
              "IPY_MODEL_4d05153b0ef14f8b9139d61f8c4ea733"
            ],
            "layout": "IPY_MODEL_3d69cbfce2e4434f83ccb040cf07fbb9"
          }
        },
        "c917cd8289934c09a1f1ab7a8c1be104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d341df37f2142db871598186e9786a7",
            "placeholder": "​",
            "style": "IPY_MODEL_c332b0cb2f1d4190a8ec59fdf308f2ea",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "421c15fcb8cb40f68cc0628341f67abc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b14b3f8e2700466aa542b7eec4653378",
            "max": 189607929,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3536a7646004762baa9fabf33e721c1",
            "value": 189607929
          }
        },
        "4d05153b0ef14f8b9139d61f8c4ea733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f22c50a0c454774a5a45482f3120975",
            "placeholder": "​",
            "style": "IPY_MODEL_50f9eda0db3945b0bdd9842cb7ff58dd",
            "value": " 190M/190M [00:07&lt;00:00, 32.8MB/s]"
          }
        },
        "3d69cbfce2e4434f83ccb040cf07fbb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d341df37f2142db871598186e9786a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c332b0cb2f1d4190a8ec59fdf308f2ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b14b3f8e2700466aa542b7eec4653378": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3536a7646004762baa9fabf33e721c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f22c50a0c454774a5a45482f3120975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50f9eda0db3945b0bdd9842cb7ff58dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56c6d8e4fcdd48eab5a22b66eb94ab13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b437db4526b4ac0933350ea0b4f864f",
              "IPY_MODEL_9a5d1e03e02549b58191e5341973c13c",
              "IPY_MODEL_39fe3e508c744d21b886b7b9e1849aee"
            ],
            "layout": "IPY_MODEL_e287191aed26450a9207ae9c11174436"
          }
        },
        "4b437db4526b4ac0933350ea0b4f864f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6032dba100e647c49ac3331b184837f4",
            "placeholder": "​",
            "style": "IPY_MODEL_a399d7f4174d4c64832a21d8ba380d60",
            "value": "model.safetensors: 100%"
          }
        },
        "9a5d1e03e02549b58191e5341973c13c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f62f3deaa7a943c09e88318ed43fb13b",
            "max": 189435040,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecb874ab490a4afd8ae9d65ac01e5d4f",
            "value": 189435040
          }
        },
        "39fe3e508c744d21b886b7b9e1849aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dad137291d3d46ba9d638be9556ffc18",
            "placeholder": "​",
            "style": "IPY_MODEL_fe424c210ef2461682475bb57de08d75",
            "value": " 189M/189M [00:05&lt;00:00, 45.1MB/s]"
          }
        },
        "e287191aed26450a9207ae9c11174436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6032dba100e647c49ac3331b184837f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a399d7f4174d4c64832a21d8ba380d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f62f3deaa7a943c09e88318ed43fb13b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecb874ab490a4afd8ae9d65ac01e5d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dad137291d3d46ba9d638be9556ffc18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe424c210ef2461682475bb57de08d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}